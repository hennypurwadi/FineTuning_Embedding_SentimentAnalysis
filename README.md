## Evaluating the Impact of Fine-Tuning Methods on Enhancing Performance in Sentiment Analysis Tasks" 

### The focus of the research is on comparing the effectiveness of fine-tuning and embedding techniques for improving sentiment analysis performance. 

### References:

Krill, P. (2024) 'OpenAI unveils new embedding models, GPT Turbo updates', InfoWorld.com, 26 Jan, NA, available: https://link-gale-com.hull.idm.oclc.org/apps/doc/A780530477/ITOF?u=unihull&sid=summon&xid=0bb62d90 [accessed 03 Aug 2024].

Liu, S., Shuai, P., Zhang, X., Chen, S., Li, L., Liu, M. (2020). Fine-Tuned Transformer Model for Sentiment Analysis. In: Li, G., Shen, H., Yuan, Y., Wang, X., Liu, H., Zhao, X. (eds) Knowledge Science, Engineering and Management. KSEM 2020. Lecture Notes in Computer Science(), vol 12275. Springer, Cham. https://doi.org/10.1007/978-3-030-55393-7_30

Nusrat, J. P., Sami, A. A., Kowsher, M., Saydul, A. M., Bairagi, A. K., Masud, M., & Baz, M. (2022). Transfer learning for sentiment analysis using BERT based supervised fine-tuning. Sensors, 22(11), 4157. doi:https://doi.org/10.3390/s22114157

PDF. (2024). Comparative analysis of transformer models for sentiment analysis in low-resource languages. International Journal of Advanced Computer Science and Applications, 15(4) doi:https://doi.org/10.14569/IJACSA.2024.0150437

Fine-Tuning Word Embeddings for Aspect-Based Sentiment Analysis. Conference paper. First Online: 29 July 2017. pp 500–508. https://link.springer.com/chapter/10.1007/978-3-319-64206-2_56

BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives. Conference paper. First Online: 16 March 2022. pp 209–218. Frederico Dias Souza & João Baptista de Oliveira e Souza Filho. https://link.springer.com/chapter/10.1007/978-3-030-98305-5_20


